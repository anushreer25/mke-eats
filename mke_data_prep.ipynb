{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515acbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milwaukee Restaurant Reddit Data Collection\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232709d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull up to 8 google reviews for each restaurant (60 total)\n",
    "df=pd.read_csv('mke_reviews.csv')\n",
    "df=df[['title','neighborhood','description','phone','reviews/0/text','reviews/0/publishedAtDate','reviews/1/text','reviews/1/publishedAtDate',\n",
    "       'reviews/2/text','reviews/2/publishedAtDate',\n",
    "       'reviews/3/text','reviews/3/publishedAtDate','reviews/4/text',\n",
    "       'reviews/4/publishedAtDate','reviews/5/text','reviews/5/publishedAtDate','reviews/6/text','reviews/6/publishedAtDate',\n",
    "       'reviews/7/text','reviews/7/publishedAtDate']]\n",
    "rest_list=df['title'].to_list()\n",
    "col_names=['title','neighborhood','description','phone','reviews/0/text','reviews/0/publishedAtDate','reviews/1/text','reviews/1/publishedAtDate',\n",
    "       'reviews/2/text','reviews/2/publishedAtDate',\n",
    "       'reviews/3/text','reviews/3/publishedAtDate','reviews/4/text',\n",
    "       'reviews/4/publishedAtDate','reviews/5/text','reviews/5/publishedAtDate','reviews/6/text','reviews/6/publishedAtDate',\n",
    "       'reviews/7/text','reviews/7/publishedAtDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read only mode: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"KvrTjF5kzjUZAu_RrKlvzw\",\n",
    "    client_secret=\"VqtjIjPhtfbZQVrbDm7KJPfl1BVPnw\",\n",
    "    user_agent=\"milwaukee_food_tracker\",\n",
    ")\n",
    "\n",
    "print(f\"Read only mode: {reddit.read_only}\")\n",
    "\n",
    "\n",
    "# r/milwaukee - main Milwaukee subreddit\n",
    "# r/wisconsin - broader Wisconsin discussions\n",
    "\n",
    "RESTAURANTS = rest_list\n",
    "\n",
    "FOOD_KEYWORDS = [\n",
    "    \"restaurant\", \"food\", \"brunch\", \"dinner\", \"lunch\",\n",
    "    \"bar\",\"drinks\", \"brewery\", \"cafe\", \"pizza\", \"burger\", \"taco\",\"sandwich\",\"vegetarian\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_restaurants_in_text(text, restaurants):\n",
    "    text_lower = text.lower()\n",
    "    matches = [r for r in restaurants if r.lower() in text_lower]\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efad1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab  posts from subreddit, KEEP ONLY posts that actually mention\n",
    "    at least one restaurant from RESTAURANTS.\n",
    "def collect_reddit_posts(subreddit_name, time_filter=\"month\", limit=500):\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    SEARCH_TERMS = RESTAURANTS + FOOD_KEYWORDS\n",
    "\n",
    "    seen_ids = set()\n",
    "\n",
    "    for term in SEARCH_TERMS:\n",
    "        print(f\"> Searching '{term}' in r/{subreddit_name}\")\n",
    "        try:\n",
    "            submissions = subreddit.search(term, time_filter=time_filter, limit=limit)\n",
    "\n",
    "            for submission in submissions:\n",
    "                if submission.id in seen_ids:\n",
    "                    continue\n",
    "                \n",
    "                full_text = (submission.title or \"\") + \" \" + (submission.selftext or \"\")\n",
    "                found = find_restaurants_in_text(full_text, RESTAURANTS)\n",
    "\n",
    "                if len(found) == 0:\n",
    "                    continue \n",
    "\n",
    "                seen_ids.add(submission.id)\n",
    "\n",
    "                data.append({\n",
    "                    \"ID\": submission.id,\n",
    "                    \"Title\": submission.title,\n",
    "                    \"Body\": submission.selftext,\n",
    "                    \"Restaurants_Mentioned\": list(set(found)),\n",
    "                    \"Score\": submission.score,\n",
    "                    \"Num_Comments\": submission.num_comments,\n",
    "                    \"Created_UTC\": datetime.fromtimestamp(submission.created_utc),\n",
    "                    \"URL\": submission.url,\n",
    "                    \"Subreddit\": subreddit_name,\n",
    "                })\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching {term}: {e}\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_restaurant_comments(submission_ids, restaurants):#only collects comments mentioning at least 1 restaurant\n",
    "\n",
    "    comments_data = []\n",
    "\n",
    "    for sub_id in submission_ids:\n",
    "        try:\n",
    "            submission = reddit.submission(id=sub_id)\n",
    "            submission.comments.replace_more(limit=0)\n",
    "\n",
    "            for comment in submission.comments.list():\n",
    "                if not comment.body:\n",
    "                    continue\n",
    "\n",
    "                found = find_restaurants_in_text(comment.body, restaurants)\n",
    "                if len(found) == 0:\n",
    "                    continue  # ❌ skip comments with no restaurant mention\n",
    "\n",
    "                comments_data.append({\n",
    "                    \"Submission_ID\": sub_id,\n",
    "                    \"Comment_Body\": comment.body,\n",
    "                    \"Restaurants_Mentioned\": list(set(found)),\n",
    "                    \"Comment_Score\": comment.score,\n",
    "                    \"Created_UTC\": datetime.fromtimestamp(comment.created_utc),\n",
    "                })\n",
    "\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error, for {sub_id}: {e}\")\n",
    "\n",
    "    return comments_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1d288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collecting from r/milwaukee ---\n",
      "> Searching 'East Town Kitchen + Bar' in r/milwaukee\n",
      "> Searching 'The National Cafe' in r/milwaukee\n",
      "> Searching 'Onesto' in r/milwaukee\n",
      "> Searching 'Easy Tyger | An Asian Gastropub' in r/milwaukee\n",
      "> Searching 'La Caribeña The best Caribbean family restaurant' in r/milwaukee\n",
      "> Searching 'State Street Pizza Pub' in r/milwaukee\n",
      "> Searching 'Screaming Tuna Milwaukee' in r/milwaukee\n",
      "> Searching 'Elsa's On the Park' in r/milwaukee\n",
      "> Searching 'Lucky Ginger' in r/milwaukee\n",
      "> Searching 'La Dama | Mexican Kitchen & Bar' in r/milwaukee\n",
      "> Searching 'Michael’s Family Restaurant' in r/milwaukee\n",
      "> Searching 'Botanas Restaurant' in r/milwaukee\n",
      "> Searching 'Blue Bat Kitchen & Tequilaria' in r/milwaukee\n",
      "> Searching 'Orenda Cafe' in r/milwaukee\n",
      "> Searching 'Copper on King' in r/milwaukee\n",
      "> Searching 'Blue Star Cafe' in r/milwaukee\n",
      "> Searching 'Harbor House' in r/milwaukee\n",
      "> Searching 'The Knick' in r/milwaukee\n",
      "> Searching 'The Diplomat' in r/milwaukee\n",
      "> Searching 'FiL FiL' in r/milwaukee\n",
      "> Searching 'Daddy's Soul Food & Grille' in r/milwaukee\n",
      "> Searching 'Merriment Social' in r/milwaukee\n",
      "> Searching 'Saint Bibiana' in r/milwaukee\n",
      "> Searching 'Tre Rivali' in r/milwaukee\n",
      "> Searching 'Casablanca' in r/milwaukee\n",
      "> Searching 'La Masa Empanada Bar' in r/milwaukee\n",
      "> Searching 'Café Benelux' in r/milwaukee\n",
      "> Searching 'Mader's Restaurant' in r/milwaukee\n",
      "> Searching 'Story Hill BKC' in r/milwaukee\n",
      "> Searching 'The Edison' in r/milwaukee\n",
      "> Searching 'Tauro Cocina' in r/milwaukee\n",
      "> Searching 'Oggie's Kitchen & Bar' in r/milwaukee\n",
      "> Searching 'Oak Barrel Public House' in r/milwaukee\n",
      "> Searching 'Mediterranean cuisine' in r/milwaukee\n",
      "> Searching 'Swingin' Door Exchange' in r/milwaukee\n",
      "> Searching 'La Chinampa' in r/milwaukee\n",
      "> Searching 'Birch' in r/milwaukee\n",
      "> Searching 'Tupelo Honey Southern Kitchen & Bar' in r/milwaukee\n",
      "> Searching 'Zarletti' in r/milwaukee\n",
      "> Searching 'Buckley's Restaurant & Bar' in r/milwaukee\n",
      "> Searching 'DOC's Commerce Smokehouse' in r/milwaukee\n",
      "> Searching 'MOTOR Bar and Restaurant' in r/milwaukee\n",
      "> Searching 'The Wicked Hop' in r/milwaukee\n",
      "> Searching 'The Capital Grille' in r/milwaukee\n",
      "> Searching 'Cavas' in r/milwaukee\n",
      "> Searching 'Twisted Fisherman' in r/milwaukee\n",
      "> Searching 'San Giorgio Pizzeria Napoletana' in r/milwaukee\n",
      "> Searching 'Camino' in r/milwaukee\n",
      "> Searching 'Uncle Wolfie's Breakfast Tavern' in r/milwaukee\n",
      "> Searching 'The Bridgewater Modern Grill' in r/milwaukee\n",
      "> Searching 'Bavette La Boucherie' in r/milwaukee\n",
      "> Searching 'Lupi & Iris' in r/milwaukee\n",
      "> Searching 'Aperitivo' in r/milwaukee\n",
      "> Searching 'Catrina Café Mke' in r/milwaukee\n",
      "> Searching 'Morel' in r/milwaukee\n",
      "> Searching 'Stella Van Buren' in r/milwaukee\n",
      "> Searching 'La Merenda' in r/milwaukee\n",
      "> Searching 'Crispy Kitchen' in r/milwaukee\n",
      "> Searching 'Sanford' in r/milwaukee\n",
      "> Searching 'The Fitz' in r/milwaukee\n",
      "> Searching 'restaurant' in r/milwaukee\n",
      "> Searching 'food' in r/milwaukee\n",
      "> Searching 'brunch' in r/milwaukee\n",
      "> Searching 'dinner' in r/milwaukee\n",
      "> Searching 'lunch' in r/milwaukee\n",
      "> Searching 'bar' in r/milwaukee\n",
      "> Searching 'drinks' in r/milwaukee\n",
      "> Searching 'brewery' in r/milwaukee\n",
      "> Searching 'cafe' in r/milwaukee\n",
      "> Searching 'pizza' in r/milwaukee\n",
      "> Searching 'burger' in r/milwaukee\n",
      "> Searching 'taco' in r/milwaukee\n",
      "> Searching 'sandwich' in r/milwaukee\n",
      "> Searching 'vegetarian' in r/milwaukee\n",
      "\n",
      "--- Collecting from r/wisconsin ---\n",
      "> Searching 'East Town Kitchen + Bar' in r/wisconsin\n",
      "> Searching 'The National Cafe' in r/wisconsin\n",
      "> Searching 'Onesto' in r/wisconsin\n",
      "> Searching 'Easy Tyger | An Asian Gastropub' in r/wisconsin\n",
      "> Searching 'La Caribeña The best Caribbean family restaurant' in r/wisconsin\n",
      "> Searching 'State Street Pizza Pub' in r/wisconsin\n",
      "> Searching 'Screaming Tuna Milwaukee' in r/wisconsin\n",
      "> Searching 'Elsa's On the Park' in r/wisconsin\n",
      "> Searching 'Lucky Ginger' in r/wisconsin\n",
      "> Searching 'La Dama | Mexican Kitchen & Bar' in r/wisconsin\n",
      "> Searching 'Michael’s Family Restaurant' in r/wisconsin\n",
      "> Searching 'Botanas Restaurant' in r/wisconsin\n",
      "> Searching 'Blue Bat Kitchen & Tequilaria' in r/wisconsin\n",
      "> Searching 'Orenda Cafe' in r/wisconsin\n",
      "> Searching 'Copper on King' in r/wisconsin\n",
      "> Searching 'Blue Star Cafe' in r/wisconsin\n",
      "> Searching 'Harbor House' in r/wisconsin\n",
      "> Searching 'The Knick' in r/wisconsin\n",
      "> Searching 'The Diplomat' in r/wisconsin\n",
      "> Searching 'FiL FiL' in r/wisconsin\n",
      "> Searching 'Daddy's Soul Food & Grille' in r/wisconsin\n",
      "> Searching 'Merriment Social' in r/wisconsin\n",
      "> Searching 'Saint Bibiana' in r/wisconsin\n",
      "> Searching 'Tre Rivali' in r/wisconsin\n",
      "> Searching 'Casablanca' in r/wisconsin\n",
      "> Searching 'La Masa Empanada Bar' in r/wisconsin\n",
      "> Searching 'Café Benelux' in r/wisconsin\n",
      "> Searching 'Mader's Restaurant' in r/wisconsin\n",
      "> Searching 'Story Hill BKC' in r/wisconsin\n",
      "> Searching 'The Edison' in r/wisconsin\n",
      "> Searching 'Tauro Cocina' in r/wisconsin\n",
      "> Searching 'Oggie's Kitchen & Bar' in r/wisconsin\n",
      "> Searching 'Oak Barrel Public House' in r/wisconsin\n",
      "> Searching 'Mediterranean cuisine' in r/wisconsin\n",
      "> Searching 'Swingin' Door Exchange' in r/wisconsin\n",
      "> Searching 'La Chinampa' in r/wisconsin\n",
      "> Searching 'Birch' in r/wisconsin\n",
      "> Searching 'Tupelo Honey Southern Kitchen & Bar' in r/wisconsin\n",
      "> Searching 'Zarletti' in r/wisconsin\n",
      "> Searching 'Buckley's Restaurant & Bar' in r/wisconsin\n",
      "> Searching 'DOC's Commerce Smokehouse' in r/wisconsin\n",
      "> Searching 'MOTOR Bar and Restaurant' in r/wisconsin\n",
      "> Searching 'The Wicked Hop' in r/wisconsin\n",
      "> Searching 'The Capital Grille' in r/wisconsin\n",
      "> Searching 'Cavas' in r/wisconsin\n",
      "> Searching 'Twisted Fisherman' in r/wisconsin\n",
      "> Searching 'San Giorgio Pizzeria Napoletana' in r/wisconsin\n",
      "> Searching 'Camino' in r/wisconsin\n",
      "> Searching 'Uncle Wolfie's Breakfast Tavern' in r/wisconsin\n",
      "> Searching 'The Bridgewater Modern Grill' in r/wisconsin\n",
      "> Searching 'Bavette La Boucherie' in r/wisconsin\n",
      "> Searching 'Lupi & Iris' in r/wisconsin\n",
      "> Searching 'Aperitivo' in r/wisconsin\n",
      "> Searching 'Catrina Café Mke' in r/wisconsin\n",
      "> Searching 'Morel' in r/wisconsin\n",
      "> Searching 'Stella Van Buren' in r/wisconsin\n",
      "> Searching 'La Merenda' in r/wisconsin\n",
      "> Searching 'Crispy Kitchen' in r/wisconsin\n",
      "> Searching 'Sanford' in r/wisconsin\n",
      "> Searching 'The Fitz' in r/wisconsin\n",
      "> Searching 'restaurant' in r/wisconsin\n",
      "> Searching 'food' in r/wisconsin\n",
      "> Searching 'brunch' in r/wisconsin\n",
      "> Searching 'dinner' in r/wisconsin\n",
      "> Searching 'lunch' in r/wisconsin\n",
      "> Searching 'bar' in r/wisconsin\n",
      "> Searching 'drinks' in r/wisconsin\n",
      "> Searching 'brewery' in r/wisconsin\n",
      "> Searching 'cafe' in r/wisconsin\n",
      "> Searching 'pizza' in r/wisconsin\n",
      "> Searching 'burger' in r/wisconsin\n",
      "> Searching 'taco' in r/wisconsin\n",
      "> Searching 'sandwich' in r/wisconsin\n",
      "> Searching 'vegetarian' in r/wisconsin\n",
      "\n",
      "Collected 65 unique restaurant-related posts.\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "all_data.extend(collect_reddit_posts(\"milwaukee\", time_filter=\"year\", limit=200))\n",
    "\n",
    "all_data.extend(collect_reddit_posts(\"wisconsin\", time_filter=\"year\", limit=200))\n",
    "\n",
    "df_posts = pd.DataFrame(all_data)\n",
    "\n",
    "len(df_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4d57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv(\"milwaukee_restaurants_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9835601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 106 restaurant-specific comments.\n"
     ]
    }
   ],
   "source": [
    "post_ids = df_posts[\"ID\"].tolist()\n",
    "\n",
    "df_comments = pd.DataFrame(\n",
    "    collect_restaurant_comments(post_ids, RESTAURANTS)\n",
    ")\n",
    "\n",
    "df_comments.to_csv(\"milwaukee_restaurants_comments.csv\", index=False)\n",
    "\n",
    "print(f\"Collected {len(df_comments)} restaurant-specific comments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f4628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East Town Kitchen + Bar</td>\n",
       "      <td>I was really worried this was going to be a ba...</td>\n",
       "      <td>2025-11-23T21:28:07.596Z</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East Town Kitchen + Bar</td>\n",
       "      <td>Food was terrible. Plates were never cleared. ...</td>\n",
       "      <td>2025-11-23T15:33:30.799Z</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East Town Kitchen + Bar</td>\n",
       "      <td>Great beer from Taylor!</td>\n",
       "      <td>2025-11-22T20:23:23.320Z</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>East Town Kitchen + Bar</td>\n",
       "      <td>Taylor did a great job accommodating our picky...</td>\n",
       "      <td>2025-11-22T19:35:39.134Z</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East Town Kitchen + Bar</td>\n",
       "      <td>Solid selection of beers on tap!</td>\n",
       "      <td>2025-11-22T19:34:58.316Z</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                restaurant                                               text  \\\n",
       "0  East Town Kitchen + Bar  I was really worried this was going to be a ba...   \n",
       "1  East Town Kitchen + Bar  Food was terrible. Plates were never cleared. ...   \n",
       "2  East Town Kitchen + Bar                            Great beer from Taylor!   \n",
       "3  East Town Kitchen + Bar  Taylor did a great job accommodating our picky...   \n",
       "4  East Town Kitchen + Bar                   Solid selection of beers on tap!   \n",
       "\n",
       "                       date  source  \n",
       "0  2025-11-23T21:28:07.596Z  google  \n",
       "1  2025-11-23T15:33:30.799Z  google  \n",
       "2  2025-11-22T20:23:23.320Z  google  \n",
       "3  2025-11-22T19:35:39.134Z  google  \n",
       "4  2025-11-22T19:34:58.316Z  google  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#google reviews flattened -> long\n",
    "\n",
    "cols = [\n",
    "    \"title\", \"neighborhood\", \"description\", \"phone\",\n",
    "    *[f\"reviews/{i}/text\" for i in range(8)],\n",
    "    *[f\"reviews/{i}/publishedAtDate\" for i in range(8)]\n",
    "]\n",
    "dft = df[cols]\n",
    "\n",
    "def reshape_google_reviews(dft):\n",
    "    rows = []\n",
    "\n",
    "    for _, row in dft.iterrows():\n",
    "        restaurant = row[\"title\"]\n",
    "\n",
    "        for i in range(8):\n",
    "            text_col = f\"reviews/{i}/text\"\n",
    "            date_col = f\"reviews/{i}/publishedAtDate\"\n",
    "\n",
    "            text = row.get(text_col)\n",
    "            date = row.get(date_col)\n",
    "\n",
    "            # skip missing reviews\n",
    "            if pd.isna(text):\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"restaurant\": restaurant,\n",
    "                \"text\": text,\n",
    "                \"date\": date,\n",
    "                \"source\": \"google\"\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_reviews = reshape_google_reviews(dft)\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POSITIVE_WORDS = {\n",
    "    'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'delicious',\n",
    "    'tasty', 'yummy', 'fresh', 'perfect', 'love', 'loved', 'best', 'awesome',\n",
    "    'favorite', 'recommend', 'must', 'outstanding', 'superb', 'incredible',\n",
    "    'exceptional', 'phenomenal', 'mouthwatering', 'scrumptious', 'delectable',\n",
    "    'savory', 'flavorful', 'tender', 'juicy', 'crispy', 'creamy', 'satisfying',\n",
    "    'hearty', 'authentic', 'cozy', 'friendly', 'attentive', 'prompt', 'clean',\n",
    "    'affordable', 'reasonable', 'worth', 'stellar', 'top-notch', 'divine',\n",
    "    'perfectly', 'well', 'exceeded', 'surpassed', 'impressed'\n",
    "}\n",
    "\n",
    "NEGATIVE_WORDS = {\n",
    "    'bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor', 'worst',\n",
    "    'overpriced', 'expensive', 'rude', 'slow', 'dirty', 'cold', 'bland',\n",
    "    'tasteless', 'dry', 'burnt', 'undercooked', 'salty', 'soggy', 'greasy',\n",
    "    'mediocre', 'average', 'meh', 'okay', 'disgusting', 'inedible',\n",
    "    'unprofessional', 'unfriendly', 'ignored', 'wait', 'crowded', 'noisy',\n",
    "    'smelly', 'stale', 'fake', 'disappointed', 'avoid', 'waste', 'rip-off',\n",
    "    'never', 'again', 'sorry', 'unfortunately', 'mess', 'chaotic', 'understaffed'\n",
    "}\n",
    "\n",
    "INTENSIFIERS = {\n",
    "    'very', 'really', 'extremely', 'incredibly', 'absolutely', 'totally',\n",
    "    'completely', 'utterly', 'especially', 'particularly', 'exceptionally'\n",
    "}\n",
    "\n",
    "NEGATION_WORDS = {\n",
    "    'not', \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"don't\", \"doesn't\", \"didn't\",\n",
    "    \"won't\", \"wouldn't\", \"couldn't\", \"shouldn't\", \"can't\", \"cannot\",\n",
    "    'never', 'no', 'none', 'nothing', 'nobody', 'nowhere', 'neither', 'nor'\n",
    "}\n",
    "\n",
    "def simple_sentiment_analysis(text):\n",
    "    \"\"\"\n",
    "    Simple lexicon-based sentiment analysis with negation handling\n",
    "    Returns sentiment score between -1 (very negative) and 1 (very positive)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return 0\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', text_lower)\n",
    "    \n",
    "    if not words:\n",
    "        return 0\n",
    "    \n",
    "    sentiment_score = 0\n",
    "    negate_next = False\n",
    "    intensify_next = False\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        # Check for negation\n",
    "        if word in NEGATION_WORDS:\n",
    "            negate_next = True\n",
    "            continue\n",
    "        \n",
    "        # Check for intensifiers\n",
    "        if word in INTENSIFIERS:\n",
    "            intensify_next = True\n",
    "            continue\n",
    "        \n",
    "        # Check for positive words\n",
    "        if word in POSITIVE_WORDS:\n",
    "            score = 1\n",
    "            if intensify_next:\n",
    "                score *= 1.5\n",
    "            if negate_next:\n",
    "                score *= -1\n",
    "            sentiment_score += score\n",
    "        \n",
    "        # Check for negative words\n",
    "        elif word in NEGATIVE_WORDS:\n",
    "            score = -1\n",
    "            if intensify_next:\n",
    "                score *= 1.5\n",
    "            if negate_next:\n",
    "                score *= -1\n",
    "            sentiment_score += score\n",
    "        \n",
    "        # Reset flags after each word\n",
    "        negate_next = False\n",
    "        intensify_next = False\n",
    "    \n",
    "    # Normalize the score to be between -1 and 1\n",
    "    normalized_score = sentiment_score / len(words)\n",
    "    return max(-1, min(1, normalized_score))\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    \"\"\"Categorize sentiment score into label\"\"\"\n",
    "    if score > 0.1:\n",
    "        return \"positive\"\n",
    "    elif score < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "435a8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['sentiment_score'] = df_posts['Body'].apply(simple_sentiment_analysis)\n",
    "df_posts['sentiment'] = df_posts['sentiment_score'].apply(categorize_sentiment)\n",
    "\n",
    "#sentiment analysis comments\n",
    "df_comments['sentiment_score'] = df_comments['Comment_Body'].apply(simple_sentiment_analysis)\n",
    "df_comments['sentiment'] = df_comments['sentiment_score'].apply(categorize_sentiment)\n",
    "\n",
    "#  sentiment analysis google reviews\n",
    "df_reviews['sentiment_score'] = df_reviews['text'].apply(simple_sentiment_analysis)\n",
    "df_reviews['sentiment'] = df_reviews['sentiment_score'].apply(categorize_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad47351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments[df_comments[\"Restaurants_Mentioned\"].str.len() == 1].assign(\n",
    "    Restaurants_Mentioned=lambda x: x[\"Restaurants_Mentioned\"].str[0]\n",
    ")\n",
    "\n",
    "df_posts = df_posts[df_posts[\"Restaurants_Mentioned\"].str.len() == 1].assign(\n",
    "    Restaurants_Mentioned=lambda x: x[\"Restaurants_Mentioned\"].str[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2db68a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_csv('google_reviews_long_format.csv')\n",
    "df_posts.to_csv('milwaukee_restaurants_posts.csv')\n",
    "df_comments.to_csv('milwaukee_restaurants_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
